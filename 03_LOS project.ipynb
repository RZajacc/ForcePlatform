{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOS Project (Limits of stability)\n",
    "It is again data measured with force platform, but the procedure is a bit more dynamic. Subjects were asked to stay still for 10 seconds, and after that lean forward as far as possible without losing a balance and stay in this position for the remaining 20 sec. This procedure divides recording into 3 phases. Initial standing, leaning forward, and end position. I phase 1, and 3, paramaters describing changes in body's Center of pressure are measured. For each trial, a chart is being made and exported into charts folder for further inspection. Additionaly excel database is being exported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy import signal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pyentrp import entropy as ent\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for text attributes (Important for aesthethics of print outs)\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! On Windows you need to replace all '/' with '\\\\'\n",
    "patternFname = 'Data/LOS_Data/'\n",
    "patternCharts = 'Charts/'\n",
    "patternFiles = 'Data/LOS_Data/*.txt'\n",
    "patternExport = 'DataBase/LOS_DB.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limits_of_stability(file):\n",
    "    \n",
    "    # Sample frequency, and frequency cut for filter\n",
    "    fs = 100\n",
    "    fc = 7\n",
    "    \n",
    "    # Open file\n",
    "    columns = ['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz']\n",
    "    df = pd.read_csv(file, skiprows=4, header=None, names=columns, encoding=\"Windows-1252\")\n",
    "       \n",
    "    #Assigning timeline for data\n",
    "    time = df.index.values / fs\n",
    "    df['Time'] = time\n",
    "        \n",
    "    #Filter definition\n",
    "    b, a = signal.butter(4, fc/(fs/2), 'low', analog=False)\n",
    "\n",
    "    #Filtering data\n",
    "    df['Fx'] = signal.filtfilt(b,a, df['Fx'])\n",
    "    df['Fy'] = signal.filtfilt(b,a, df['Fy'])\n",
    "    df['Fz'] = signal.filtfilt(b,a, df['Fz'])\n",
    "    df['Mx'] = signal.filtfilt(b,a, df['Mx'])\n",
    "    df['My'] = signal.filtfilt(b,a, df['My'])\n",
    "    df['Mz'] = signal.filtfilt(b,a, df['Mz'])\n",
    "        \n",
    "    #Define COP in both directions\n",
    "    cpx = -(df['My'].values / df['Fz'].values)*100\n",
    "    df['COPX'] = cpx\n",
    "    cpy = -(-df['Mx'].values / df['Fz'] * 100)\n",
    "    df['COPY'] = cpy\n",
    "        \n",
    "    #Values to start searching for crossection of linear regression\n",
    "    ph1 = 800\n",
    "    ph2 = 1500\n",
    "    dh = 500\n",
    "        \n",
    "    # Get coefficients\n",
    "    a1, b1 = np.polyfit(df['Time'][:ph1].values, df['COPY'][:ph1].values, 1) \n",
    "    a3, b3 = np.polyfit(df['Time'][ph2:].values, df['COPY'][ph2:], 1)\n",
    "\n",
    "    # Get regresion lines\n",
    "    ywh1 = a1 * df['Time'].values + b1\n",
    "    ywh3 = a3 * df['Time'].values + b3\n",
    "        \n",
    "    # Adjust positions of start/end of phases\n",
    "    pph2 = 0\n",
    "    pph1 = 0\n",
    "\n",
    "    # Find the point where regression line cross the moment of forward lean\n",
    "    for ind in range(ph1, len(df)):\n",
    "        if (ywh3[ind] - df['COPY'][ind]) > 0:\n",
    "            pph2 = ind\n",
    "        else:\n",
    "            if (abs(ywh3[ind] - df['COPY'][ind]) < abs( ywh3[ind-1] - df['COPY'][ind-1])):\n",
    "                pph2 = ind\n",
    "                break    \n",
    "\n",
    "    # Same for 1st phase\n",
    "    for ind in range(ph2, 0, -1):\n",
    "        if (ywh1[ind] - df['COPY'][ind]) < 0:\n",
    "            pph1 = ind\n",
    "        else:\n",
    "            if ( abs(ywh1[ind] - df['COPY'][ind]) < abs(ywh1[ind+1] - df['COPY'][ind+1]) ):\n",
    "                pph1 = ind\n",
    "                break    \n",
    "                    \n",
    "    # Find regression line for 2nd phase\n",
    "    a2, b2 = np.polyfit(df['Time'][pph1:pph2].values, df['COPY'][pph1:pph2].values, 1)\n",
    "    ywh2 = b2 + a2 * df['Time'][pph1:pph2]\n",
    "        \n",
    "    # Define regression line again with new time limits\n",
    "    a1, b1 = np.polyfit(df['Time'][:pph1].values, df['COPY'][:pph1].values, 1)\n",
    "    a3, b3 = np.polyfit(df['Time'][pph2:].values, df['COPY'][pph2:].values, 1)\n",
    "\n",
    "    # Get regresion lines\n",
    "    ywh1 = a1 * df['Time'].values + b1\n",
    "    ywh3 = a3 * df['Time'].values + b3\n",
    "        \n",
    "    #Calculating COP characteristics in anterior-posterior direction (AP) Phase 1\n",
    "    f1_raCOP_AP = df['COPY'][:pph1].max() - df['COPY'][:pph1].min()\n",
    "    f1_mean_AP = df['COPY'][:pph1].mean()\n",
    "    f1_stdCOP_AP = df['COPY'][:pph1].std()\n",
    "    f1_max_AP = df['COPY'][:pph1].max()\n",
    "    f1_min_AP = df['COPY'][:pph1].min()\n",
    "    f1_lenCOP_AP = 0\n",
    "\n",
    "    for i in range(0, len(df['COPY'][:pph1])) :\n",
    "        f1_lenCOP_AP += abs(df['COPY'][i+1] - (df['COPY'][i]) ) \n",
    "\n",
    "    f1_vCOP_AP = f1_lenCOP_AP / ( len(df['COPY'][:pph1]) / fs )     \n",
    "    f1_sampeEn_AP = ent.sample_entropy(df['COPY'][:pph1], 3, 0.2)\n",
    "\n",
    "    #Calculating COP characteristics in anterior-posterior direction (AP) Phase 2\n",
    "    f2_raCOP_AP = df['COPY'][pph1:pph2].max() - df['COPY'][pph1:pph2].min()\n",
    "    f2_mean_AP = df['COPY'][pph1:pph2].mean()\n",
    "    f2_stdCOP_AP = df['COPY'][pph1:pph2].std()\n",
    "    f2_max_AP = df['COPY'][pph1:pph2].max()\n",
    "    f2_min_AP = df['COPY'][pph1:pph2].min()\n",
    "\n",
    "    #Calculating COP characteristics in anterior-posterior direction (AP) Phase 3\n",
    "    f3_raCOP_AP = df['COPY'][pph2:].max() - df['COPY'][pph2:].min()\n",
    "    f3_mean_AP = df['COPY'][pph2:].mean()\n",
    "    f3_stdCOP_AP = df['COPY'][pph2:].std()\n",
    "    f3_max_AP = df['COPY'][pph2:].max()\n",
    "    f3_min_AP = df['COPY'][pph2:].min()\n",
    "    f3_lenCOP_AP = 0\n",
    "\n",
    "    for i in range(pph2, len(df['COPY'])-1) :\n",
    "        f3_lenCOP_AP += abs(df['COPY'][i+1] - (df['COPY'][i]) ) \n",
    "\n",
    "    f3_vCOP_AP = f3_lenCOP_AP / ( len(df['COPY'][pph2:]) / fs )     \n",
    "    f3_sampeEn_AP = ent.sample_entropy(df['COPY'][pph2:], 3, 0.2)\n",
    "\n",
    "    #Calculating COP characteristics in anterior-posterior direction (ML) Phase 1\n",
    "    f1_raCOP_ML = df['COPX'][:pph1].max() - df['COPX'][:pph1].min()\n",
    "    f1_mean_ML = df['COPX'][:pph1].mean()\n",
    "    f1_stdCOP_ML = df['COPX'][:pph1].std()\n",
    "    f1_max_ML = df['COPX'][:pph1].max()\n",
    "    f1_min_ML = df['COPX'][:pph1].min()\n",
    "    f1_lenCOP_ML = 0\n",
    "   \n",
    "    for i in range(0, len(df['COPX'][:pph1])) :\n",
    "        f1_lenCOP_ML += abs(df['COPX'][i+1] - (df['COPX'][i]) ) \n",
    "\n",
    "    f1_vCOP_ML = f1_lenCOP_ML / ( len(df['COPX'][:pph1]) / fs )     \n",
    "    f1_sampeEn_ML = ent.sample_entropy(df['COPX'][:pph1], 3, 0.2)\n",
    "\n",
    "    #Calculating COP characteristics in anterior-posterior direction (ML) Phase 3\n",
    "    f3_raCOP_ML = df['COPX'][pph2:].max() - df['COPX'][pph2:].min()\n",
    "    f3_mean_ML = df['COPX'][pph2:].mean()\n",
    "    f3_stdCOP_ML = df['COPX'][pph2:].std()\n",
    "    f3_max_ML = df['COPX'][pph2:].max()\n",
    "    f3_min_ML = df['COPX'][pph2:].min()\n",
    "    f3_lenCOP_ML = 0\n",
    "   \n",
    "    for i in range(pph2, len(df['COPX'])-1) :\n",
    "        f3_lenCOP_ML += abs(df['COPX'][i+1] - (df['COPX'][i]) ) \n",
    "\n",
    "    f3_vCOP_ML = f3_lenCOP_ML / ( len(df['COPX'][pph2:]) / fs )     \n",
    "    f3_sampeEn_ML = ent.sample_entropy(df['COPX'][pph2:], 3, 0.2)\n",
    "        \n",
    "    # Define variables for LOS - time of phases and max lean forwarard value\n",
    "    T1P = 0.0\n",
    "    T1K = (pph1-1) / 100\n",
    "    T2P = pph1 / 100\n",
    "    T2K = (pph2-1) / 100\n",
    "    T3P = pph2 / 100\n",
    "    T3K = len(df) / 100\n",
    "    R1 = df['COPY'][pph2:].mean() - df['COPY'][:pph1].mean()\n",
    "    R3 = df['COPY'].max() - df['COPY'].min()\n",
    "        \n",
    "    # Get name and trial number from file path\n",
    "    fname = file.replace(patternFname  , '')\n",
    "    fnameSplit = fname.split(\"_\")\n",
    "    t_num = fnameSplit[0]\n",
    "    s_num = fnameSplit[2].split(\".\")\n",
    "    name = \"_\".join([fnameSplit[1], s_num[0]])\n",
    "        \n",
    "    # Saving figure tagged with subject name and trial number\n",
    "    fig = plt.figure(figsize = (12,6))\n",
    "    plt.style.use('ggplot')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(df['Time'], df['COPY'], linewidth = 2, color = 'dodgerblue')\n",
    "    ax.plot(df['Time'][:pph1], ywh1[:pph1], color='red', linewidth=1.5)\n",
    "    ax.plot(df['Time'][pph1:pph2], ywh2, color='red', linewidth=1.5)\n",
    "    ax.plot(df['Time'][pph2:], ywh3[pph2:], color='red', linewidth=1.5)\n",
    "    ax.set(title=\"Trial nr: \" + str(t_num) + '; ' + ' Subject: ' + name , xlabel = 'Time[s]', ylabel = 'Center of pressure[cm]')\n",
    "    fig.savefig(patternCharts + str(t_num) + '_' + name + '.png')\n",
    "    plt.close()\n",
    "        \n",
    "    # Saving results into list of dictionaries\n",
    "    res_ap = {'Subject': name, 'Trial': t_num, 'F1_raCOP': f1_raCOP_AP, 'F1_stdCOP': f1_stdCOP_AP, 'F1_lenCOP': f1_lenCOP_AP, \n",
    "          'F1_vCOP': f1_vCOP_AP, 'F1_sampEn': f1_sampeEn_AP[0], 'F1_stdSampEn': f1_sampeEn_AP[1], 'F3_raCOP': f3_raCOP_AP, \n",
    "          'F3_stdCOP': f3_stdCOP_AP, 'F3_lenCOP': f3_lenCOP_AP, 'F3_vCOP': f3_vCOP_AP, 'F3_sampEn': f3_sampeEn_AP[0], \n",
    "          'F3_stdSampEn': f3_sampeEn_AP[1]}\n",
    "    res_ml = {'Subject': name, 'Trial': t_num, 'F1_raCOP': f1_raCOP_ML, 'F1_stdCOP': f1_stdCOP_ML, 'F1_lenCOP': f1_lenCOP_ML, \n",
    "          'F1_vCOP': f1_vCOP_ML, 'F1_sampEn': f1_sampeEn_ML[0], 'F1_stdSampEn': f1_sampeEn_ML[1], 'F3_raCOP': f3_raCOP_ML, \n",
    "          'F3_stdCOP': f3_stdCOP_ML, 'F3_lenCOP': f3_lenCOP_ML, 'F3_vCOP': f3_vCOP_ML, 'F3_sampEn': f3_sampeEn_ML[0], \n",
    "          'F3_stdSampEn': f3_sampeEn_ML[1]}\n",
    "    res_los = {'Subject': name, 'Trial': t_num, 'T1P': T1P, 'T1K': T1K, 'B1': a1, 'Mean1': f1_mean_AP, 'Std1': f1_stdCOP_AP, \n",
    "           'Max1': f1_max_AP, 'Min1': f1_min_AP, 'Range1': f1_raCOP_AP, 'T2P': T2P, 'T2K': T2K, 'B2': a2, 'Mean2': f2_mean_AP, \n",
    "           'Std2': f2_stdCOP_AP, 'Max2': f2_max_AP, 'Min2': f2_min_AP, 'Range2': f2_raCOP_AP, 'T3P': T3P, 'T3K': T3K, 'B3': a3, \n",
    "           'Mean3': f3_mean_AP, 'Std3': f3_stdCOP_AP, 'Max3': f3_max_AP, 'Min3': f3_min_AP, 'Range3': f3_raCOP_AP, \n",
    "           'R1': R1, 'R3': R3}\n",
    "        \n",
    "    res_bundle = [res_ap, res_ml, res_los]\n",
    "        \n",
    "    return res_bundle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of Result dataframes\n",
    "df_ap = pd.DataFrame(columns=['Subject', 'Trial', 'F1_raCOP', 'F1_stdCOP', 'F1_lenCOP', 'F1_vCOP', 'F1_sampEn', 'F1_stdSampEn',\n",
    "                                                'F3_raCOP', 'F3_stdCOP', 'F3_lenCOP', 'F3_vCOP', 'F3_sampEn', 'F3_stdSampEn'])\n",
    "df_ml = pd.DataFrame(columns=['Subject', 'Trial','F1_raCOP', 'F1_stdCOP', 'F1_lenCOP', 'F1_vCOP', 'F1_sampEn', 'F1_stdSampEn',\n",
    "                                               'F3_raCOP', 'F3_stdCOP', 'F3_lenCOP', 'F3_vCOP', 'F3_sampEn', 'F3_stdSampEn'])\n",
    "df_los = pd.DataFrame(columns=['Subject', 'Trial','T1P', 'T1K', 'B1', 'Mean1', 'Std1', 'Max1', 'Min1', 'Range1',\n",
    "                                                'T2P', 'T2K', 'B2', 'Mean2', 'Std2', 'Max2', 'Min2', 'Range2',\n",
    "                                                'T3P', 'T3K', 'B3', 'Mean3', 'Std3', 'Max3', 'Min3', 'Range3', 'R1', 'R3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14009/2988541185.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ap = pd.concat([df_ap, pd.DataFrame([data[0]])], ignore_index=True)\n",
      "/tmp/ipykernel_14009/2988541185.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ml = pd.concat([df_ml, pd.DataFrame([data[1]])], ignore_index=True)\n",
      "/tmp/ipykernel_14009/2988541185.py:14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_los = pd.concat([df_los, pd.DataFrame([data[2]])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTotal progress : \u001b[0m100%\r"
     ]
    }
   ],
   "source": [
    "# Getting all results\n",
    "\n",
    "files = glob.glob(patternFiles)\n",
    "\n",
    "#Counter for files (only for information about progress)\n",
    "fileCount = 1\n",
    "fileAmount = len(files)\n",
    "\n",
    "for file in files:\n",
    "    #print(file)\n",
    "    data = limits_of_stability(file)\n",
    "    df_ap = pd.concat([df_ap, pd.DataFrame([data[0]])], ignore_index=True)\n",
    "    df_ml = pd.concat([df_ml, pd.DataFrame([data[1]])], ignore_index=True)\n",
    "    df_los = pd.concat([df_los, pd.DataFrame([data[2]])], ignore_index=True)\n",
    "    \n",
    "    \n",
    "    #Information about progress\n",
    "    print(color.BOLD + 'Total progress : ' + color.END + str(int(fileCount/fileAmount  *100)) + '%', end = '\\r')\n",
    "    fileCount = fileCount + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ap.sort_values(by=[\"Subject\", \"Trial\"], inplace=True)\n",
    "df_ml.sort_values(by=[\"Subject\", \"Trial\"], inplace=True)\n",
    "df_los.sort_values(by=[\"Subject\", \"Trial\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(patternExport) as writer:  \n",
    "    df_ap.to_excel(writer, sheet_name='AP', index=False)\n",
    "    df_ml.to_excel(writer, sheet_name='ML', index=False)\n",
    "    df_los.to_excel(writer, sheet_name='LOS', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forcePlate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
